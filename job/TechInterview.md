# Tech Interview

## Algorithm

## Computer Science

### Computer Architecture

#### 컴퓨터의 구성

#### 중앙처리장치(CPU) 작동 원리

#### 캐시 메모리(Cache Memory)

    - 속도가 빠른 장치와 느린 장치에서 속도 차이에 따른 병목 현상을 줄이기 위한 메모리를 말한다.
        - ex1) CPU 코어와 메모리 사이의 병복 현상 완화
        - ex2) 웹 브라우저 캐시 파일은, 하드디스크와 웹피이지 사이의 병목 현상을 완화
    - 속도라는 장점을 얻지만, 용량이 적기도 하고 비용이 비싼 점이 있다.
    - 캐시 메모리 작동 원리
        - 참조 지역성 원리 존재
            - 시간 지역성
                - for나 while 같은 반복문에 사용하는 조건 변수처럼 한번 참조된 데이터는 잠시후 또 참조될 가능성이 높음
            - 공간 지역성
                - A[0], A[1]과 같은 연속 접근 시, 참조된 데이터 근처에 있는 데이터가 잠시후 또 사용될 가능성이 높음
    - 캐시 미스 경우 3가지
        - Cold miss
            - 해당 메모리 주소를 처음 불러서 나는 미스
        - Conflict miss
            - 주소 할당 문제
                - 캐시 메모리에 A와 B데이터를 저장해야되는데, A와 B가 같은 캐시 메모리 주소에 할당 되어 있어서 나는 미스
        - Capacity miss
            - 공간 문제
                - 캐시 메모리 공간이 부족해서 나는 미스
        - 캐시 크기를 키워서 문제를 해결하려면, 캐시 접근속도가 느려지고 파워를 많이 먹는 단점이 생김
    - 구조 및 작동 방식
        - Direct Mapped Cache
            - DRAM의 여러 주소가 캐시 메모리의 한 주소에 대응되는 다대일 방식
            - 장점: 간단하고 빠른
            - 단점: Confict Miss 발생
        - Fully Associative Cache
            - 비어있는 캐시 메모리가 있으면, 마음대로 주소를 저장하는 방식
            - 저장할 때는 매우 간단하지만, 찾을 때가 문제
        - Set Associative Cache
            - Direct + Fully 방식
                - 특정 행을 지정하고, 그 행안의 어떤 열이든 비어있을 때 저장
            - Direct에 비해 검색 속도는 느리지만, 저장이 빠르고 Fully에 비해 저장이 느린 대신 검색이 빠른 중간형

#### 고정 소수점 & 부동 소수점

컴퓨터에서 실수를 표현하는 방법은 `고정 소수점`과 `부동 소수점` 두가지 방식이 존재한다.

1. 고정 소수점(Fixed Point)
    - 소수점이 찍힐 위치를 미리 정해놓고 소수를 표현하는 방식 (정수 + 소수)
    - 장점: 실수를 정수부와 소수부로 표현하여 단순
    - 단점: 표현의 범위가 너무 적어서 활용하기 힘들다. (정수부는 15bit, 소수부는 16bit)

2. 부동 소수점(Floating Point)
    - 실수를 가수부 + 지수부로 표현한다.
        - 가수: 실수의 실제값 표현
        - 지수: 크기를 표현함. 가수의 어디쯤에 소수점이 있는지 나타냄
    - 지수의 값에 따라 소수점이 움직이는 방식을 활용한 실수 표현 방법이다.
        - 즉, 소수점의 위치가 고정되어 있지 않는다.
    - 장점: 표현할 수 있는 수의 범위가 넓어진다. (현재 대부분 시스템에서 활용 중)
    - 단점: 오차가 발생할 수 있다. (부동소수점으로 표현할 수 있는 방법이 매우 다양함)

#### 패리티 비트 & 해밍 코드

#### ARM 프로세서

    - 프로세서란?
        - 메모리에 저장된 명령어들을 실행하는 유한 상태 오토마톤

### Data Structure

#### 배열 (Array)

#### 연결 리스트 (Linked List)

    - 연속적인 메모리 위치에 저장되지 않는 선형 데이터 구조 (포인터를 사용해서 연결 된다)
    - 각 노드는 데이터 필드와 다음 노드에 대한 참조를 포함하는 노드로 구성
    - 왜 Linked List를 사용하나?
        - 배열은 비슷한 유형의 선형 데이터를 저장하는데 사용할 수 있지만 제한 사항이 있음
            1. 배열의 크기가 고정되어 있어 미리 요소의 수에 대해 할당을 받아야 함
            2. 새로운 요소를 삽입하는 것은 비용이 많이 듬 (공간을 만들고, 기존 요소 전부 이동)
        - 장점:
            1. 동적 크기
            2. 삽입/삭제 용이
        - 단점:
            1. 임의로 액세스를 허용할 수 없음. 즉, 첫 번째 노드부터 순차적으로 요소에 액세스 해야함 (이진 검색 수행 불가능)
            2. 포인터의 여분의 메모리 공간이 목록의 각 요소에 필요

#### Array & ArrayList & LinkedList

#### 스택 & 큐
    - 스택 (Stack)
        - 입력과 출력이 한 곳(방향)으로 제한
        - LIFO (Last In First Out, 후입선출)
        - 언제 사용?
            - 함수의 콜스택, 문자열 역순 출력, 연산자 후위표기법
        - method
            - push()
            - pop()
            - isEmpty()
            - isFull()
            + 스택 포인터(SP)
        - push 와 pop 할 때는 해당 위치를 알고 있어야 하므로 기억하고 있는 '스택 포인터(SP)'가 필요함
            - 스택 포인터는 다음 값이 들어갈 위치를 가리키고 있음 (처음 기본값은 -1)

    - 큐 (Queue)
        - 입력과 출력을 한 쪽 끝(front, rear)으로 제한
        - FIFO (First In First Out, 선입선출)
        - 언제 사용?
            - 버퍼, 마구 입력된 것을 처리하지 못하고 있는 상황, BFS
        - method
            - enQueue()
            - deQueue()
            - isEmpty()
            - isFull()
        - 데이터를 넣고 뺄 때 해당 값의 위치를 기억해야 함. (스택에서 스택 포인터와 같은 역할)
            - 이 위치를 기억하고 있는게 front 와 rear
            - front: deQueue 할 위치 기억
            - rear: enQueue 할 위치 기억
        - 일반 큐의 단점: 큐에 빈 메모리가 남아 있어도, 꽉 차있는것으로 판단할 수도 있음 (rear 가 끝에 도달했을 때)
            - 일반 큐를 개선한 것이 '원형 큐'
                - 논리적으로 배열의 처음과 끝이 연결되어 있는 것으로 간주함!
                - 원형 큐는 초기 공백 상태일 때 front와 rear가 0
                - 공백, 포화 상태를 쉽게 구분하기 위해 자리 하나를 항상 비워둠
                - enQueue 시, 가득 찼다면 꽉 차 있는 상태에서 enQueue를 했기 때문에 overflow
                - deQueue를 할 때 공백이면 underflow
                - 원형 큐의 단점 : 메모리 공간은 잘 활용하지만, 배열로 구현되어 있기 때문에 큐의 크기가 제한
            - 원형 큐를 개선한 것이 '연결리스트 큐'
                - 연결리스트 큐는 크기가 제한이 없고 삽입, 삭제가 편리

#### 힙 (Heap)
    - 우선순위 큐를 위해 만들어진 자료구조
    - 우선순위 큐
        - 우선순위의 개념을 큐에 도입한 자료구조
            - 데이터들이 우선순위를 가지고 있음. 우선순위가 높은 데이터가 먼저 나감
        - 스택은 LIFO, 큐는 FIFO
        - 언제 사용?
            - 시뮬레이션 시스템, 작업 스케줄링, 수치해석 계산
        - 우선순위 큐는 배열, 연결리스트, 힙으로 구현 (힙으로 구현이 가장 효율적!)
        - 힙 → 삽입 : O(logn) , 삭제 : O(logn)
    - 힙(Heap)
        - 완전 이진 트리의 일종
            - 여러 값 중, 최대값과 최소값을 빠르게 찾아내도록 만들어진 자료구조
        - 반정렬 상태
        - 힙 트리는 중복된 값 허용 (이진 탐색 트리는 중복값 허용X)
        - 힙 종류
            - 최대 힙(max heap)
                - 부모 노드의 키 값이 자식 노드의 키 값보다 크거나 같은 완전 이진 트리
                - 구현
                    - 힙을 저장하는 표준적인 자료구조는 배열
                    - 구현을 쉽게 하기 위해 배열의 첫번째 인덱스인 0은 사용되지 않음
                    - 특정 위치의 노드 번호는 새로운 노드가 추가되어도 변하지 않음
                    - (ex. 루트 노드(1)의 오른쪽 노드 번호는 항상 3)
        - 힙의 삽입
            1.힙에 새로운 요소가 들어오면, 일단 새로운 노드를 힙의 마지막 노드에 삽입
            2.새로운 노드를 부모 노드들과 교환
            - 부모 노드는 자신의 인덱스의 /2 이므로, 비교하고 자신이 더 크면 swap하는 방식
        - 힙의 삭제
            1.최대 힙에서 최대값은 루트 노드이므로 루트 노드가 삭제됨 (최대 힙에서 삭제 연산은 최대값 요소를 삭제하는 것)
            2.삭제된 루트 노드에는 힙의 마지막 노드를 가져옴
            3.힙을 재구성



#### 이진 탐색 트리

#### 해시 (Hash)
    - 데이터를 효율적으로 관리하기 위해, 임의의 길이 데이터를 고정된 길이의 데이터로 매핑하는 것
    - 해시 함수를 구현하여 데이터 값을 해시 값으로 매핑한다.
    - 결국 데이터가 많아지면, 다른 데이터가 같은 해시 값으로 충돌나는 현상이 발생함 'collision' 현상
    - 그래도 해시 테이블을 쓰는 이유는?
        - 적은 자원으로 많은 데이터를 효율적으로 관리하기 위해
        - 하드디스크나, 클라우드에 존재하는 무한한 데이터들을 유한한 개수의 해시값으로 매핑하면 작은 메모리로도 프로세스 관리가 가능해짐!
    - 언제나 동일한 해시값 리턴, index를 알면 빠른 데이터 검색이 가능해짐
    - 해시테이블의 시간복잡도 O(1) - (이진탐색트리는 O(logN))
    - 충돌 문제 해결
        1. 체이닝 : 연결리스트로 노드를 계속 추가해나가는 방식 (제한 없이 계속 연결 가능, but 메모리 문제)
        2. Open Addressing : 해시 함수로 얻은 주소가 아닌 다른 주소에 데이터를 저장할 수 있도록 허용 (해당 키 값에 저장되어있으면 다음 주소에 저장)
        3. 선형 탐사 : 정해진 고정 폭으로 옮겨 해시값의 중복을 피함
        4. 제곱 탐사 : 정해진 고정 폭을 제곱수로 옮겨 해시값의 중복을 피함





#### 트라이 (Trie)

####  B Tree & B+ Tree

### Operating System

#### 운영체제란?
일반적으로 `하드웨어를 관리하고, 응용 프로그램과 하드웨어 사이에서 인터페이스 역할을 하며 시스템의 동작을 제어하는 시스템 소프트웨어` 로 정의한다

운영체제는 시스템의 자원과 동작을 관리하는 소프트웨어다.

(시스템의 역할 구분에 따라 운영체제의 역할은 모두 다를 수 있다.)

운영체제를 큰 틀로 나눠보면 아래와 같다.

1. 프로세스 관리
    - 프로세스, 스레드
    - 스케줄링
    - 동기화
    - IPC 통신

2. 저장장치 관리
    - 메모리 관리
    - 가상 메모리
    - 파일 시스템

3. 네트워킹
    - TCP/IP
    - 기타 프로토콜

4. 사용자 관리
    - 계정 관리
    - 접근권한 관리

5. 디바이스 드라이버
    - 순차접근 장치
    - 임의접근 장치
    - 네트워크 장치

#### 프로세스와 스레드

__프로세스__: 프로그램을 메모리 상에서 실행중인 작업
__스레드__: 프로세스 안에서 실행되는 여러 흐름 단위

기본적으로 프로세스마다 최소 1개의 스레드 소유 (메인 스레드 포함)

##### 프로세스는 각각 별도의 주소공간 할당 (독립적)
- Code : 코드 자체를 구성하는 메모리 영역(프로그램 명령)
- Data : 전역변수, 정적변수, 배열 등 (초기화된 데이터)
- Heap : 동적 할당 시 사용 (new(), mallock() 등)
- Stack : 지역변수, 매개변수, 리턴 값 (임시 메모리 영역)

스레드는 Stack만 따로 할당 받고 나머지 영역은 서로 공유

하나의 프로세스가 생성될 때, 기본적으로 하나의 스레드 같이 생성

__프로세스는 자신만의 고유 공간과 자원을 할당받아 사용__하는데 반해, __스레드는 다른 스레드와 공간, 자원을 공유하면서 사용__하는 차이가 존재함

__멀티프로세스__: 하나의 컴퓨터에 여러 CPU 장착 → 하나 이상의 프로세스들을 동시에 처리(병렬)

장점 : 안전성 (메모리 침범 문제를 OS 차원에서 해결)
단점 : 각각 독립된 메모리 영역을 갖고 있어, 작업량 많을 수록 오버헤드 발생. Context Switching으로 인한 성능 저하


__Context Switching이란__?

프로세스의 상태 정보를 저장하고 복원하는 일련의 과정

즉, 동작 중인 프로세스가 대기하면서 해당 프로세스의 상태를 보관하고, 대기하고 있던 다음 순번의 프로세스가 동작하면서 이전에 보관했던 프로세스 상태를 복구하는 과정을 말함

→ 프로세스는 각 독립된 메모리 영역을 할당받아 사용되므로, 캐시 메모리 초기화와 같은 무거운 작업이 진행되었을 때 오버헤드가 발생할 문제가 존재함

__멀티 스레드__: 하나의 응용 프로그램에서 여러 스레드를 구성해 각 스레드가 하나의 작업을 처리하는 것

스레드들이 공유 메모리를 통해 다수의 작업을 동시에 처리하도록 해줌

장점 : 독립적인 프로세스에 비해 공유 메모리만큼의 시간, 자원 손실이 감소 전역 변수와 정적 변수에 대한 자료 공유 가능

단점 : 안전성 문제. 하나의 스레드가 데이터 공간 망가뜨리면, 모든 스레드가 작동 불능 상태 (공유 메모리를 갖기 때문)

멀티스레드의 안전성에 대한 단점은 Critical Section 기법을 통해 대비함

하나의 스레드가 공유 데이터 값을 변경하는 시점에 다른 스레드가 그 값을 읽으려할 때 발생하는 문제를 해결하기 위한 동기화 과정

`상호 배제, 진행, 한정된 대기를 충족해야함`
