# Tech Interview

source: [Tech Interview](https://gyoogle.dev/blog/computer-science/operating-system/Process%20vs%20Thread.html)

## Algorithm

## Computer Science

### Computer Architecture

#### 컴퓨터의 구성

#### 중앙처리장치(CPU) 작동 원리

#### 캐시 메모리(Cache Memory)

    - 속도가 빠른 장치와 느린 장치에서 속도 차이에 따른 병목 현상을 줄이기 위한 메모리를 말한다.
        - ex1) CPU 코어와 메모리 사이의 병복 현상 완화
        - ex2) 웹 브라우저 캐시 파일은, 하드디스크와 웹피이지 사이의 병목 현상을 완화
    - 속도라는 장점을 얻지만, 용량이 적기도 하고 비용이 비싼 점이 있다.
    - 캐시 메모리 작동 원리
        - 참조 지역성 원리 존재
            - 시간 지역성
                - for나 while 같은 반복문에 사용하는 조건 변수처럼 한번 참조된 데이터는 잠시후 또 참조될 가능성이 높음
            - 공간 지역성
                - A[0], A[1]과 같은 연속 접근 시, 참조된 데이터 근처에 있는 데이터가 잠시후 또 사용될 가능성이 높음
    - 캐시 미스 경우 3가지
        - Cold miss
            - 해당 메모리 주소를 처음 불러서 나는 미스
        - Conflict miss
            - 주소 할당 문제
                - 캐시 메모리에 A와 B데이터를 저장해야되는데, A와 B가 같은 캐시 메모리 주소에 할당 되어 있어서 나는 미스
        - Capacity miss
            - 공간 문제
                - 캐시 메모리 공간이 부족해서 나는 미스
        - 캐시 크기를 키워서 문제를 해결하려면, 캐시 접근속도가 느려지고 파워를 많이 먹는 단점이 생김
    - 구조 및 작동 방식
        - Direct Mapped Cache
            - DRAM의 여러 주소가 캐시 메모리의 한 주소에 대응되는 다대일 방식
            - 장점: 간단하고 빠른
            - 단점: Confict Miss 발생
        - Fully Associative Cache
            - 비어있는 캐시 메모리가 있으면, 마음대로 주소를 저장하는 방식
            - 저장할 때는 매우 간단하지만, 찾을 때가 문제
        - Set Associative Cache
            - Direct + Fully 방식
                - 특정 행을 지정하고, 그 행안의 어떤 열이든 비어있을 때 저장
            - Direct에 비해 검색 속도는 느리지만, 저장이 빠르고 Fully에 비해 저장이 느린 대신 검색이 빠른 중간형

#### 고정 소수점 & 부동 소수점

컴퓨터에서 실수를 표현하는 방법은 `고정 소수점`과 `부동 소수점` 두가지 방식이 존재한다.

1. 고정 소수점(Fixed Point)

   - 소수점이 찍힐 위치를 미리 정해놓고 소수를 표현하는 방식 (정수 + 소수)
   - 장점: 실수를 정수부와 소수부로 표현하여 단순
   - 단점: 표현의 범위가 너무 적어서 활용하기 힘들다. (정수부는 15bit, 소수부는 16bit)

2. 부동 소수점(Floating Point)
   - 실수를 가수부 + 지수부로 표현한다.
     - 가수: 실수의 실제값 표현
     - 지수: 크기를 표현함. 가수의 어디쯤에 소수점이 있는지 나타냄
   - 지수의 값에 따라 소수점이 움직이는 방식을 활용한 실수 표현 방법이다.
     - 즉, 소수점의 위치가 고정되어 있지 않는다.
   - 장점: 표현할 수 있는 수의 범위가 넓어진다. (현재 대부분 시스템에서 활용 중)
   - 단점: 오차가 발생할 수 있다. (부동소수점으로 표현할 수 있는 방법이 매우 다양함)

#### 패리티 비트 & 해밍 코드

#### ARM 프로세서

    - 프로세서란?
        - 메모리에 저장된 명령어들을 실행하는 유한 상태 오토마톤

### Data Structure

#### 배열 (Array)

#### 연결 리스트 (Linked List)

    - 연속적인 메모리 위치에 저장되지 않는 선형 데이터 구조 (포인터를 사용해서 연결 된다)
    - 각 노드는 데이터 필드와 다음 노드에 대한 참조를 포함하는 노드로 구성
    - 왜 Linked List를 사용하나?
        - 배열은 비슷한 유형의 선형 데이터를 저장하는데 사용할 수 있지만 제한 사항이 있음
            1. 배열의 크기가 고정되어 있어 미리 요소의 수에 대해 할당을 받아야 함
            2. 새로운 요소를 삽입하는 것은 비용이 많이 듬 (공간을 만들고, 기존 요소 전부 이동)
        - 장점:
            1. 동적 크기
            2. 삽입/삭제 용이
        - 단점:
            1. 임의로 액세스를 허용할 수 없음. 즉, 첫 번째 노드부터 순차적으로 요소에 액세스 해야함 (이진 검색 수행 불가능)
            2. 포인터의 여분의 메모리 공간이 목록의 각 요소에 필요

#### Array & ArrayList & LinkedList

#### 스택 & 큐

    - 스택 (Stack)
        - 입력과 출력이 한 곳(방향)으로 제한
        - LIFO (Last In First Out, 후입선출)
        - 언제 사용?
            - 함수의 콜스택, 문자열 역순 출력, 연산자 후위표기법
        - method
            - push()
            - pop()
            - isEmpty()
            - isFull()
            + 스택 포인터(SP)
        - push 와 pop 할 때는 해당 위치를 알고 있어야 하므로 기억하고 있는 '스택 포인터(SP)'가 필요함
            - 스택 포인터는 다음 값이 들어갈 위치를 가리키고 있음 (처음 기본값은 -1)

    - 큐 (Queue)
        - 입력과 출력을 한 쪽 끝(front, rear)으로 제한
        - FIFO (First In First Out, 선입선출)
        - 언제 사용?
            - 버퍼, 마구 입력된 것을 처리하지 못하고 있는 상황, BFS
        - method
            - enQueue()
            - deQueue()
            - isEmpty()
            - isFull()
        - 데이터를 넣고 뺄 때 해당 값의 위치를 기억해야 함. (스택에서 스택 포인터와 같은 역할)
            - 이 위치를 기억하고 있는게 front 와 rear
            - front: deQueue 할 위치 기억
            - rear: enQueue 할 위치 기억
        - 일반 큐의 단점: 큐에 빈 메모리가 남아 있어도, 꽉 차있는것으로 판단할 수도 있음 (rear 가 끝에 도달했을 때)
            - 일반 큐를 개선한 것이 '원형 큐'
                - 논리적으로 배열의 처음과 끝이 연결되어 있는 것으로 간주함!
                - 원형 큐는 초기 공백 상태일 때 front와 rear가 0
                - 공백, 포화 상태를 쉽게 구분하기 위해 자리 하나를 항상 비워둠
                - enQueue 시, 가득 찼다면 꽉 차 있는 상태에서 enQueue를 했기 때문에 overflow
                - deQueue를 할 때 공백이면 underflow
                - 원형 큐의 단점 : 메모리 공간은 잘 활용하지만, 배열로 구현되어 있기 때문에 큐의 크기가 제한
            - 원형 큐를 개선한 것이 '연결리스트 큐'
                - 연결리스트 큐는 크기가 제한이 없고 삽입, 삭제가 편리

#### 힙 (Heap)

    - 우선순위 큐를 위해 만들어진 자료구조
    - 우선순위 큐
        - 우선순위의 개념을 큐에 도입한 자료구조
            - 데이터들이 우선순위를 가지고 있음. 우선순위가 높은 데이터가 먼저 나감
        - 스택은 LIFO, 큐는 FIFO
        - 언제 사용?
            - 시뮬레이션 시스템, 작업 스케줄링, 수치해석 계산
        - 우선순위 큐는 배열, 연결리스트, 힙으로 구현 (힙으로 구현이 가장 효율적!)
        - 힙 → 삽입 : O(logn) , 삭제 : O(logn)
    - 힙(Heap)
        - 완전 이진 트리의 일종
            - 여러 값 중, 최대값과 최소값을 빠르게 찾아내도록 만들어진 자료구조
        - 반정렬 상태
        - 힙 트리는 중복된 값 허용 (이진 탐색 트리는 중복값 허용X)
        - 힙 종류
            - 최대 힙(max heap)
                - 부모 노드의 키 값이 자식 노드의 키 값보다 크거나 같은 완전 이진 트리
                - 구현
                    - 힙을 저장하는 표준적인 자료구조는 배열
                    - 구현을 쉽게 하기 위해 배열의 첫번째 인덱스인 0은 사용되지 않음
                    - 특정 위치의 노드 번호는 새로운 노드가 추가되어도 변하지 않음
                    - (ex. 루트 노드(1)의 오른쪽 노드 번호는 항상 3)
        - 힙의 삽입
            1.힙에 새로운 요소가 들어오면, 일단 새로운 노드를 힙의 마지막 노드에 삽입
            2.새로운 노드를 부모 노드들과 교환
            - 부모 노드는 자신의 인덱스의 /2 이므로, 비교하고 자신이 더 크면 swap하는 방식
        - 힙의 삭제
            1.최대 힙에서 최대값은 루트 노드이므로 루트 노드가 삭제됨 (최대 힙에서 삭제 연산은 최대값 요소를 삭제하는 것)
            2.삭제된 루트 노드에는 힙의 마지막 노드를 가져옴
            3.힙을 재구성

#### 이진 탐색 트리

#### 해시 (Hash)

    - 데이터를 효율적으로 관리하기 위해, 임의의 길이 데이터를 고정된 길이의 데이터로 매핑하는 것
    - 해시 함수를 구현하여 데이터 값을 해시 값으로 매핑한다.
    - 결국 데이터가 많아지면, 다른 데이터가 같은 해시 값으로 충돌나는 현상이 발생함 'collision' 현상
    - 그래도 해시 테이블을 쓰는 이유는?
        - 적은 자원으로 많은 데이터를 효율적으로 관리하기 위해
        - 하드디스크나, 클라우드에 존재하는 무한한 데이터들을 유한한 개수의 해시값으로 매핑하면 작은 메모리로도 프로세스 관리가 가능해짐!
    - 언제나 동일한 해시값 리턴, index를 알면 빠른 데이터 검색이 가능해짐
    - 해시테이블의 시간복잡도 O(1) - (이진탐색트리는 O(logN))
    - 충돌 문제 해결
        1. 체이닝 : 연결리스트로 노드를 계속 추가해나가는 방식 (제한 없이 계속 연결 가능, but 메모리 문제)
        2. Open Addressing : 해시 함수로 얻은 주소가 아닌 다른 주소에 데이터를 저장할 수 있도록 허용 (해당 키 값에 저장되어있으면 다음 주소에 저장)
        3. 선형 탐사 : 정해진 고정 폭으로 옮겨 해시값의 중복을 피함
        4. 제곱 탐사 : 정해진 고정 폭을 제곱수로 옮겨 해시값의 중복을 피함

#### 트라이 (Trie)

문자열에서 검색을 빠르게 도와주는 자료구조

#### B Tree & B+ Tree

**이진 트리**는 하나의 부모가 두 개의 자식밖에 가지질 못하고,
균형이 맞지 않으면 검색 효율이 선형검색 급으로 떨어진다.
하지만 이진 트리 구조의 간결함과 균형만 맞다면 검색, 삽입, 삭제 모두 O(logN)의 성능을 보이는 장점이 있기 때문에
계속 개선시키기 위한 노력이 이루어지고 있다.

##### B Tree

데이터베이스, 파일 시스템에서 널리 사용되는 트리 자료구조의 일종이다.

이진 트리를 확장해서, 더 많은 수의 자식을 가질 수 있게 일반화 시킨 것이 B-Tree

##### B+ Tree

데이터의 빠른 접근을 위한 인덱스 역할만 하는 비단말 노드(not Leaf)가 추가로 있음

(기존의 B-Tree와 데이터의 연결리스트로 구현된 색인구조)

B-Tree의 변형 구조로, index 부분과 leaf 노드로 구성된 순차 데이터 부분으로 이루어진다. 인덱스 부분의 key 값은 leaf에 있는 key 값을 직접 찾아가는데 사용함.

**장점**
블럭 사이즈를 더 많이 이용할 수 있음 (key 값에 대한 하드디스크 액세스 주소가 없기 때문)

leaf 노드끼리 연결 리스트로 연결되어 있어서 범위 탐색에 매우 유리함

**단점**
B-tree의 경우 최상 케이스에서는 루트에서 끝날 수 있지만, B+tree는 무조건 leaf 노드까지 내려가봐야 함

**B-Tree & B+ Tree**
B-tree는 각 노드에 데이터가 저장됨

B+tree는 index 노드와 leaf 노드로 분리되어 저장됨

(또한, leaf 노드는 서로 연결되어 있어서 임의접근이나 순차접근 모두 성능이 우수함)

B-tree는 각 노드에서 key와 data 모두 들어갈 수 있고, data는 disk block으로 포인터가 될 수 있음

B+tree는 각 노드에서 key만 들어감. 따라서 data는 모두 leaf 노드에만 존재

B+tree는 add와 delete가 모두 leaf 노드에서만 이루어짐

#### B Tree & B+ Tree

### Operating System

#### 운영체제란?

일반적으로 `하드웨어를 관리하고, 응용 프로그램과 하드웨어 사이에서 인터페이스 역할을 하며 시스템의 동작을 제어하는 시스템 소프트웨어` 로 정의한다

운영체제는 시스템의 자원과 동작을 관리하는 소프트웨어다.

(시스템의 역할 구분에 따라 운영체제의 역할은 모두 다를 수 있다.)

운영체제를 큰 틀로 나눠보면 아래와 같다.

1. 프로세스 관리

   - 프로세스, 스레드
   - 스케줄링
   - 동기화
   - IPC 통신

2. 저장장치 관리

   - 메모리 관리
   - 가상 메모리
   - 파일 시스템

3. 네트워킹

   - TCP/IP
   - 기타 프로토콜

4. 사용자 관리

   - 계정 관리
   - 접근권한 관리

5. 디바이스 드라이버
   - 순차접근 장치
   - 임의접근 장치
   - 네트워크 장치

#### 프로세스와 스레드

**프로세스**: 프로그램을 메모리 상에서 실행중인 작업
**스레드**: 프로세스 안에서 실행되는 여러 흐름 단위

기본적으로 프로세스마다 최소 1개의 스레드 소유 (메인 스레드 포함)

##### 프로세스는 각각 별도의 주소공간 할당 (독립적)

- Code : 코드 자체를 구성하는 메모리 영역(프로그램 명령)
- Data : 전역변수, 정적변수, 배열 등 (초기화된 데이터)
- Heap : 동적 할당 시 사용 (new(), mallock() 등)
- Stack : 지역변수, 매개변수, 리턴 값 (임시 메모리 영역)

스레드는 Stack만 따로 할당 받고 나머지 영역은 서로 공유

하나의 프로세스가 생성될 때, 기본적으로 하나의 스레드 같이 생성

**프로세스는 자신만의 고유 공간과 자원을 할당받아 사용**하는데 반해, **스레드는 다른 스레드와 공간, 자원을 공유하면서 사용**하는 차이가 존재함

**멀티프로세스**: 하나의 컴퓨터에 여러 CPU 장착 → 하나 이상의 프로세스들을 동시에 처리(병렬)

장점 : 안전성 (메모리 침범 문제를 OS 차원에서 해결)
단점 : 각각 독립된 메모리 영역을 갖고 있어, 작업량 많을 수록 오버헤드 발생. Context Switching으로 인한 성능 저하

**Context Switching이란**?

프로세스의 상태 정보를 저장하고 복원하는 일련의 과정

즉, 동작 중인 프로세스가 대기하면서 해당 프로세스의 상태를 보관하고, 대기하고 있던 다음 순번의 프로세스가 동작하면서 이전에 보관했던 프로세스 상태를 복구하는 과정을 말함

→ 프로세스는 각 독립된 메모리 영역을 할당받아 사용되므로, 캐시 메모리 초기화와 같은 무거운 작업이 진행되었을 때 오버헤드가 발생할 문제가 존재함

**멀티 스레드**: 하나의 응용 프로그램에서 여러 스레드를 구성해 각 스레드가 하나의 작업을 처리하는 것

스레드들이 공유 메모리를 통해 다수의 작업을 동시에 처리하도록 해줌

장점 : 독립적인 프로세스에 비해 공유 메모리만큼의 시간, 자원 손실이 감소 전역 변수와 정적 변수에 대한 자료 공유 가능

단점 : 안전성 문제. 하나의 스레드가 데이터 공간 망가뜨리면, 모든 스레드가 작동 불능 상태 (공유 메모리를 갖기 때문)

멀티스레드의 안전성에 대한 단점은 Critical Section 기법을 통해 대비함

하나의 스레드가 공유 데이터 값을 변경하는 시점에 다른 스레드가 그 값을 읽으려할 때 발생하는 문제를 해결하기 위한 동기화 과정

`상호 배제, 진행, 한정된 대기를 충족해야함`

#### 프로세스의 주소 공간

프로그램이 CPU에 의해 실행됨 -> 프로세스가 생성되고 메모리에 **프로세스 주소 공간**이 할당됨

프로세스 주소 공간에는 코드, 데이터, 스택으로 이루어져 있다.

- **코드 Segment**: 프로그램 소스 코드 저장
- **데이터 Segment**: 전역 변수 저장
- **스택 Segment**: 함수, 지역 변수 저장

**_왜 이렇게 구역을 나눈건가요?_**

최대한 데이터를 공유하여 메모리 사용량을 줄여야 함.

Code는 같은 프로그램 자체에서는 모두 같은 내용이기 때문에
따로 관리하여 공유한다.

Stack과 data를 나눈 이유는,
스택 구조의 특성과 전역 변수의 활용성을 위한 것이다.

프로그램의 함수와 지역 변수는,
LIFO(가장 나중에 들어간게 먼저 나옴)특성을 가진 스택에서 실행된다.

따라서 이 함수들 안에서 공통으로 사용하는 '전역 함수'는
따로 지정해주면 메모리를 아낄 수 있다.

#### 인터럽트 (Interrupt)

**정의**
프로그램을 실행하는 도중에 예기치 않은 상황이 발생할 경우
현재 실행 중인 작업을 즉시 중단하고, 발생된 상황을 우선 처리한 후
실행 중이던 작업으로 복귀하여 계속 처리하는 것

지금 수행 중인 일보다 더 중요한 일(ex. 입출력, 우선 순위 연산 등)이 발생하면 그 일을 먼저 처리하고 나서 하던 일을 계속해야한다.

외부/내부 인터럽트는 `CPU의 하드웨어 신호에 의해 발생`

소프트웨어 인터럽트는 `명령어의 수행에 의해 발생`

##### 인터럽트 발생 처리 과정

1. 주 프로그램 실행
2. 인터럽트 발생
3. 복귀주소 저장
4. 인터럽트 벡터로 점프
5. 인터럽트 처리
6. 인터럽트 처리완료
7. 복귀주소 로드
8. 마지막에 실행되던 주소로 점프
9. 주 프로그램 실행

주 프로그램이 실행되다가 인터럽트가 발생했다.

현재 수행 중인 프로그램을 멈추고, 상태 레지스터와 PC 등을 스택에 잠시 저장한 뒤에 인터럽트 서비스 루틴으로 간다. (잠시 저장하는 이유는, 인터럽트 서비스 루틴이 끝난 뒤 다시 원래 작업으로 돌아와야 하기 때문)

만약 인터럽트 기능이 없었다면, 컨트롤러는 특정한 어떤 일을 할 시기를 알기 위해 계속 체크를 해야 한다. (이를 폴링(Polling)이라고 한다)

폴링을 하는 시간에는 원래 하던 일에 집중할 수가 없게 되어 많은 기능을 제대로 수행하지 못하는 단점이 있었다.

즉, 컨트롤러가 입력을 받아들이는 방법(우선순위 판별방법)에는 두가지가 있다.

- **폴링 방식**
  사용자가 명령어를 사용해 입력 핀의 값을 계속 읽어 변화를 알아내는 방식

인터럽트 요청 플래그를 차례로 비교하여 우선순위가 가장 높은 인터럽트 자원을 찾아 이에 맞는 인터럽트 서비스 루틴을 수행한다. (하드웨어에 비해 속도 느림)

- **인터럽트 방식**
  MCU 자체가 하드웨적으로 변화를 체크하여 변화 시에만 일정한 동작을 하는 방식

      - Daisy Chain
      - 병렬 우선순위 부여

인터럽트 방식은 하드웨어로 지원을 받아야 하는 제약이 있지만, 폴링에 비해 신속하게 대응하는 것이 가능하다. 따라서 실시간 대응이 필요할 때는 필수적인 기능이다.

즉, 인터럽트는 발생시기를 예측하기 힘든 경우에 컨트롤러가 가장 빠르게 대응할 수 있는 방법이다.

#### 프로세스 주소 공간

**프로그램이 CPU에 의해 실행됨 → 프로세스가 생성되고 메모리에 프로세스 주소 공간이 할당됨**

프로세스 주소 공간에는 코드, 데이터, 스택으로 이루어져 있다.

- 코드 Segment : 프로그램 소스 코드 저장
- 데이터 Segment : 전역 변수 저장
- 스택 Segment : 함수, 지역 변수 저장

왜 이렇게 구역을 나눈건가요?

최대한 데이터를 공유하여 메모리 사용량을 줄여야 한다.
Code는 같은 프로그램 자체에서는 모두 같은 내용이기 때문에 따로 관리하여 공유한다.
Stack과 data를 나눈 이유는, 스택 구조의 특성과 전역 변수의 활용성을 위한 것이다.
프로그램의 함수와 지역 변수는, LIFO(가장 나중에 들어간게 먼저 나옴)특성을 가진 스택에서 실행된다.
따라서 이 함수들 안에서 공통으로 사용하는 '전역 함수'는 따로 지정해주면 메모리를 아낄 수 있다.

#### 인터럽트(Interrupt)

**정의**: 프로그램을 실행하는 도중에 예기치 않은 상황이 발생할 경우 현재 실행 중인 작업을 즉시 중단하고, 발생된 상황을 우선 처리한 후 실행 중이던 작업으로 복귀하여 계속 처리하는 것

지금 수행 중인 일보다 더 중요한 일(ex. 입출력, 우선 순위 연산 등)이 발생하면 그 일을 먼저 처리하고 나서 하던 일을 계속해야한다.

외부/내부 인터럽트는 CPU의 하드웨어 신호에 의해 발생

소프트웨어 인터럽트는 명령어의 수행에 의해 발생

즉, 인터럽트는 발생시기를 예측하기 힘든 경우에 컨트롤러가 가장 빠르게 대응할 수 있는 방법이다.

#### 시스템 콜(System Call)

- wait
  - child 프로세스가 종료될 때까지 기다리는 작업
  - async 함수의 await 와 비슷!

#### PCB & Context Switching

#### IPC(Inter Process Communication)

프로세스는 독립적으로 실행된다. 즉, 독립 되어있다는 것은 다른 프로세스에게 영향을 받지 않는다고 말할 수 있다. (스레드는 프로세스 안에서 자원을 공유하므로 영향을 받는다)

이런 독립적 구조를 가진 프로세스 간의 통신을 해야 하는 상황이 있을 것이다. 이를 가능하도록 해주는 것이 바로 IPC 통신이다.

프로세스는 커널이 제공하는 IPC 설비를 이용해 프로세스간 통신을 할 수 있게 된다.

**커널이란?**

`운영체제의 핵심적인 부분으로, 다른 모든 부분에 여러 기본적인 서비스를 제공해줌`

#### CPU 스케줄링 (CPU Scheduling)

1. 스케줄링
   CPU 를 잘 사용하기 위해 프로세스를 잘 배정하기

- 조건 : 오버헤드 ↓ / 사용률 ↑ / 기아 현상 ↓
- 목표
  1. `Batch System`: 가능하면 많은 일을 수행. 시간(time) 보단 처리량(throughout)이 중요
  2. `Interactive System`: 빠른 응답 시간. 적은 대기 시간.
  3. `Real-time System`: 기한(deadline) 맞추기.

2. 선점 / 비선점 스케줄링

3. 프로세스 상태

4. CPU 스케줄링의 종류

#### 데드락(DeadLock)

프로세스가 자원을 얻지 못해서 다음 처리를 하지 못하는 상태

'교착 상태'라고도 부름

시스템적으로 한정된 자원을 여러 곳에서 사용하려고 할 때 발생

#### 경쟁 상태(Race Condition)

공유 자원에 대해 여러 프로세스가 동시에 접근할 때, 결과값에 영향을 줄 수 있는 상태

동시 접근 시 자료의 일관성을 해치는 결과가 나타남

#### 세마포어(Semaphore) & 뮤텍스(Mutex)
